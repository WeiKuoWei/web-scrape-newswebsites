{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "import json\n",
    "\n",
    "site_list = [\"bbc\", \"cnn\", \"foxnews\", \"nationalreview\", \"washingtontimes\", \"newsweek\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_json(file_path):\n",
    "    data = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                # Load each line as a separate JSON object\n",
    "                json_object = json.loads(line)\n",
    "                data.append(json_object)\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle possible json decoding errors\n",
    "                continue\n",
    "\n",
    "    # Creating a DataFrame from the list of dictionaries\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Selecting specific columns to include in the final DataFrame\n",
    "    df_json = df[[\"category\", \"headline\", \"link\", \"short_description\", \"date\"]]\n",
    "    return df_json\n",
    "    # with open(file_path, \"r\") as f:\n",
    "    #     data = json.load(f)\n",
    "    # # Ensuring each entry is a dictionary and extracting them directly\n",
    "    # data = [entry for entry in data if isinstance(entry, dict)]\n",
    "    \n",
    "    # # Creating a DataFrame from the list of dictionaries\n",
    "    # df = pd.DataFrame(data)\n",
    "    \n",
    "    # # Selecting specific columns to include in the final DataFrame\n",
    "    # df_json = df[[\"category\", \"headline\", \"link\", \"short_description\", \"date\"]]\n",
    "    # return df_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanDF(df_json):\n",
    "    # clean the data\n",
    "    # drop the main text that is empty\n",
    "    df_json = df_json.dropna(subset=[\"category\", \"headline\", \"short_description\"])\n",
    "\n",
    "    # drop the duplicates\n",
    "    df_json = df_json.drop_duplicates(subset=[\"category\", \"headline\", \"short_description\"])\n",
    "\n",
    "    # add a new column based on the length of the main text\n",
    "    df_json[\"headline_len\"] = df_json[\"headline\"].apply(lambda x: len(x))\n",
    "\n",
    "    # add a new column based on the length of the main text\n",
    "    df_json[\"short_description_len\"] = df_json[\"short_description\"].apply(lambda x: len(x))\n",
    "\n",
    "    # sort\n",
    "    df_json = df_json.sort_values(by=\"date\", ascending=True)\n",
    "\n",
    "    return df_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_json = \"data/News_Category_Dataset_v3.json\"\n",
    "df_json = open_json(file_path_json)\n",
    "df_json = cleanDF(df_json)\n",
    "\n",
    "df_json.to_json(\"data/articles_all/words_category.json\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fr/tgw5syk508j35cyfwv4bhgq00000gn/T/ipykernel_14504/2010804212.py:8: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/fr/tgw5syk508j35cyfwv4bhgq00000gn/T/ipykernel_14504/2010804212.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/fr/tgw5syk508j35cyfwv4bhgq00000gn/T/ipykernel_14504/2010804212.py:12: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/fr/tgw5syk508j35cyfwv4bhgq00000gn/T/ipykernel_14504/2010804212.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/fr/tgw5syk508j35cyfwv4bhgq00000gn/T/ipykernel_14504/2010804212.py:16: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/fr/tgw5syk508j35cyfwv4bhgq00000gn/T/ipykernel_14504/2010804212.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/fr/tgw5syk508j35cyfwv4bhgq00000gn/T/ipykernel_14504/2010804212.py:20: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/fr/tgw5syk508j35cyfwv4bhgq00000gn/T/ipykernel_14504/2010804212.py:23: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/fr/tgw5syk508j35cyfwv4bhgq00000gn/T/ipykernel_14504/2010804212.py:24: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/fr/tgw5syk508j35cyfwv4bhgq00000gn/T/ipykernel_14504/2010804212.py:28: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/fr/tgw5syk508j35cyfwv4bhgq00000gn/T/ipykernel_14504/2010804212.py:31: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/fr/tgw5syk508j35cyfwv4bhgq00000gn/T/ipykernel_14504/2010804212.py:32: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/fr/tgw5syk508j35cyfwv4bhgq00000gn/T/ipykernel_14504/2010804212.py:35: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/fr/tgw5syk508j35cyfwv4bhgq00000gn/T/ipykernel_14504/2010804212.py:36: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/fr/tgw5syk508j35cyfwv4bhgq00000gn/T/ipykernel_14504/2010804212.py:39: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/fr/tgw5syk508j35cyfwv4bhgq00000gn/T/ipykernel_14504/2010804212.py:40: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/fr/tgw5syk508j35cyfwv4bhgq00000gn/T/ipykernel_14504/2010804212.py:43: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/fr/tgw5syk508j35cyfwv4bhgq00000gn/T/ipykernel_14504/2010804212.py:44: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "df_temp = df_json[[\"headline\", \"short_description\", \"category\"]].copy()\n",
    "\n",
    "#only keep the crime category\n",
    "df_crime = df_temp[df_temp[\"category\"] == \"CRIME\"]\n",
    "df_crime.dropna(inplace=True)\n",
    "\n",
    "# parse the title and description into lower case\n",
    "df_crime[\"headline\"] = df_crime[\"headline\"].str.lower()\n",
    "df_crime[\"short_description\"] = df_crime[\"short_description\"].str.lower()\n",
    "\n",
    "# remove the punctuation\n",
    "df_crime[\"headline\"] = df_crime[\"headline\"].str.replace(r'[^\\w\\s]','')\n",
    "df_crime[\"short_description\"] = df_crime[\"short_description\"].str.replace(r'[^\\w\\s]','')\n",
    "\n",
    "# remove the stop words\n",
    "df_crime[\"headline\"] = df_crime[\"headline\"].apply(lambda x: \" \".join([word for word in x.split() if word not in STOP_WORDS]))\n",
    "df_crime[\"short_description\"] = df_crime[\"short_description\"].apply(lambda x: \" \".join([word for word in x.split() if word not in STOP_WORDS]))\n",
    "\n",
    "# remove the numbers\n",
    "df_crime[\"headline\"] = df_crime[\"headline\"].str.replace(r'\\d+', '')\n",
    "df_crime[\"short_description\"] = df_crime[\"short_description\"].str.replace(r'\\d+', '')\n",
    "\n",
    "#only keep the science category\n",
    "df_science = df_temp[df_temp[\"category\"] == \"SCIENCE\"]\n",
    "df_science.dropna(inplace=True)\n",
    "\n",
    "# parse the title and description into lower case\n",
    "df_science[\"headline\"] = df_science[\"headline\"].str.lower()\n",
    "df_science[\"short_description\"] = df_science[\"short_description\"].str.lower()\n",
    "\n",
    "# remove the punctuation\n",
    "df_science[\"headline\"] = df_science[\"headline\"].str.replace(r'[^\\w\\s]','')\n",
    "df_science[\"short_description\"] = df_science[\"short_description\"].str.replace(r'[^\\w\\s]','')\n",
    "\n",
    "# remove the stop words\n",
    "df_science[\"headline\"] = df_science[\"headline\"].apply(lambda x: \" \".join([word for word in x.split() if word not in STOP_WORDS]))\n",
    "df_science[\"short_description\"] = df_science[\"short_description\"].apply(lambda x: \" \".join([word for word in x.split() if word not in STOP_WORDS]))\n",
    "\n",
    "# remove the numbers\n",
    "df_science[\"headline\"] = df_science[\"headline\"].str.replace(r'\\d+', '')\n",
    "df_science[\"short_description\"] = df_science[\"short_description\"].str.replace(r'\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Function to count word frequencies\n",
    "def count_word_frequencies(text):\n",
    "    # Split the text into words and count the occurrences of each word\n",
    "    word_counts = Counter(text.split())\n",
    "    return word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 headline  \\\n",
      "208213  karen swift's funeral planned saturday homicid...   \n",
      "208133  tim cole, convict exonerated death, gets texas...   \n",
      "208134       subject gun control, government wins justice   \n",
      "207545  hannah kelly, pastor's daughter, dies accident...   \n",
      "207481  george huguely murder trial: jurors deliberate...   \n",
      "\n",
      "                                     headline_word_counts  \\\n",
      "208213  {'karen': 1, 'swift's': 1, 'funeral': 1, 'plan...   \n",
      "208133  {'tim': 1, 'cole,': 1, 'convict': 1, 'exonerat...   \n",
      "208134  {'subject': 1, 'gun': 1, 'control,': 1, 'gover...   \n",
      "207545  {'hannah': 1, 'kelly,': 1, 'pastor's': 1, 'dau...   \n",
      "207481  {'george': 1, 'huguely': 1, 'murder': 1, 'tria...   \n",
      "\n",
      "                                        short_description  \\\n",
      "208213  police released cause death case confirmed inv...   \n",
      "208133  legislature created timothy cole advisory pane...   \n",
      "208134  i'm advocate gun control, knee-jerk opponent n...   \n",
      "207545  20-year-old hannah kelley died saturday mornin...   \n",
      "207481  usa today noted huguely, cried earlier points,...   \n",
      "\n",
      "                            short_description_word_counts  \n",
      "208213  {'police': 1, 'released': 1, 'cause': 1, 'deat...  \n",
      "208133  {'legislature': 1, 'created': 1, 'timothy': 1,...  \n",
      "208134  {'i'm': 1, 'advocate': 1, 'gun': 1, 'control,'...  \n",
      "207545  {'20-year-old': 1, 'hannah': 1, 'kelley': 1, '...  \n",
      "207481  {'usa': 1, 'today': 1, 'noted': 1, 'huguely,':...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fr/tgw5syk508j35cyfwv4bhgq00000gn/T/ipykernel_14504/1607594776.py:2: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/fr/tgw5syk508j35cyfwv4bhgq00000gn/T/ipykernel_14504/1607594776.py:3: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the title and description columns\n",
    "df_crime[\"headline_word_counts\"] = df_crime[\"headline\"].apply(count_word_frequencies)\n",
    "df_crime[\"short_description_word_counts\"] = df_crime[\"short_description\"].apply(count_word_frequencies)\n",
    "print(df_crime[[\"headline\", \"headline_word_counts\", \"short_description\", \"short_description_word_counts\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 headline  \\\n",
      "209489  russian cargo ship docks international space s...   \n",
      "209490  robots play catch, starring agile justin rolli...   \n",
      "209491   thomas edison voted iconic inventor u.s. history   \n",
      "209492  aurora borealis caused huge solar storm shimme...   \n",
      "209427  space shuttle challenger disaster marks 26th a...   \n",
      "\n",
      "                                     headline_word_counts  \\\n",
      "209489  {'russian': 1, 'cargo': 1, 'ship': 1, 'docks':...   \n",
      "209490  {'robots': 1, 'play': 1, 'catch,': 1, 'starrin...   \n",
      "209491  {'thomas': 1, 'edison': 1, 'voted': 1, 'iconic...   \n",
      "209492  {'aurora': 1, 'borealis': 1, 'caused': 1, 'hug...   \n",
      "209427  {'space': 1, 'shuttle': 1, 'challenger': 1, 'd...   \n",
      "\n",
      "                                        short_description  \\\n",
      "209489  gallery: space station's expedition 30 mission...   \n",
      "209490  image 1: throw hizook reports, dlr started rol...   \n",
      "209491  doesn't mean jobs lacks fans wake death year. ...   \n",
      "209492  aurora borealis typically seen high northern l...   \n",
      "209427  later day, president reagan returned airwaves ...   \n",
      "\n",
      "                            short_description_word_counts  \n",
      "209489  {'gallery:': 1, 'space': 1, 'station's': 1, 'e...  \n",
      "209490  {'image': 1, '1:': 1, 'throw': 1, 'hizook': 1,...  \n",
      "209491  {'doesn't': 1, 'mean': 1, 'jobs': 1, 'lacks': ...  \n",
      "209492  {'aurora': 1, 'borealis': 1, 'typically': 1, '...  \n",
      "209427  {'later': 1, 'day,': 1, 'president': 1, 'reaga...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fr/tgw5syk508j35cyfwv4bhgq00000gn/T/ipykernel_14504/641472430.py:2: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/fr/tgw5syk508j35cyfwv4bhgq00000gn/T/ipykernel_14504/641472430.py:3: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the title and description columns\n",
    "df_science[\"headline_word_counts\"] = df_science[\"headline\"].apply(count_word_frequencies)\n",
    "df_science[\"short_description_word_counts\"] = df_science[\"short_description\"].apply(count_word_frequencies)\n",
    "print(df_science[[\"headline\", \"headline_word_counts\", \"short_description\", \"short_description_word_counts\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words related to crime:\n",
      "police: 456\n",
      "shooting: 254\n",
      "cops: 184\n",
      "killed: 174\n",
      "allegedly: 165\n",
      "accused: 161\n",
      "arrested: 151\n",
      "suspect: 148\n",
      "death: 144\n",
      "shot: 134\n",
      "dead: 126\n",
      "murder: 119\n",
      "cop: 107\n",
      "charged: 105\n",
      "officer: 102\n",
      "killing: 102\n",
      "prison: 87\n",
      "missing: 80\n",
      "gun: 79\n",
      "alleged: 64\n",
      "dies: 62\n",
      "guilty: 60\n",
      "shooter: 60\n",
      "case: 57\n",
      "fatally: 57\n",
      "trial: 55\n",
      "attack: 54\n",
      "officers: 54\n",
      "injured: 51\n",
      "charges: 50\n",
      "kills: 49\n",
      "shoots: 46\n",
      "gets: 45\n",
      "body: 44\n",
      "arrest: 43\n",
      "fbi: 41\n",
      "black: 41\n",
      "suspected: 40\n",
      "sentenced: 39\n",
      "killer: 39\n",
      "life: 38\n",
      "kill: 38\n",
      "dead,: 38\n",
      "rape: 37\n",
      "crime: 34\n",
      "fatal: 34\n",
      "caught: 33\n",
      "convicted: 33\n",
      "assault: 32\n",
      "gunman: 32\n",
      "deadly: 32\n",
      "faces: 31\n",
      "face: 31\n",
      "Top words related to science:\n",
      "scientists: 154\n",
      "space: 144\n",
      "study: 125\n",
      "nasa: 105\n",
      "science: 100\n",
      "earth: 70\n",
      "mars: 70\n",
      "here's: 60\n",
      "suggests: 59\n",
      "like: 53\n",
      "moon: 48\n",
      "ancient: 48\n",
      "brain: 45\n",
      "solar: 41\n",
      "planet: 41\n",
      "research: 39\n",
      "life: 39\n",
      "way: 37\n",
      "help: 36\n",
      "world: 35\n",
      "photos: 34\n",
      "watch:: 33\n",
      "time: 32\n",
      "nasa's: 32\n",
      "discovered: 32\n",
      "rocket: 31\n",
      "climate: 31\n",
      "big: 29\n",
      "mission: 29\n",
      "change: 29\n",
      "star: 27\n",
      "watch: 27\n",
      "alien: 25\n",
      "find: 25\n",
      "sky: 25\n",
      "human: 25\n",
      "neil: 25\n",
      "red: 24\n",
      "rover: 24\n",
      "spacecraft: 24\n",
      "mystery: 24\n",
      "asteroid: 23\n",
      "researchers: 22\n",
      "black: 22\n",
      "astronomers: 21\n",
      "telescope: 21\n",
      "meteor: 21\n",
      "astronaut: 20\n",
      "mysterious: 20\n",
      "universe: 20\n",
      "humans: 20\n",
      "planets: 19\n",
      "launch: 19\n",
      "look: 19\n",
      "degrasse: 19\n",
      "station: 18\n",
      "scientific: 18\n",
      "water: 18\n",
      "spacex: 18\n",
      "giant: 18\n",
      "light: 18\n",
      "actually: 18\n",
      "sea: 18\n",
      "world's: 17\n",
      "makes: 17\n",
      "astronauts: 17\n",
      "better: 17\n",
      "evolution: 17\n",
      "eclipse: 17\n",
      "night: 17\n",
      "amazing: 17\n",
      "reveal: 17\n",
      "tyson: 17\n",
      "reveals: 17\n",
      "face: 17\n",
      "day: 16\n",
      "looks: 16\n",
      "huge: 15\n",
      "suggest: 15\n",
      "sun: 15\n",
      "galaxy: 15\n",
      "curiosity: 15\n",
      "future: 15\n",
      "rare: 15\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Define a set of non-related words\n",
    "non_related_words = {\n",
    "    'new', 'florida', 'texas', 'nyc', 'california', 'says', '2', 'idaho', 'chicago',\n",
    "    'georgia', 'carolina', 'york', 'city', 'video', 'car', 'home', 'years', 'family',\n",
    "    'los', 'mom', 'angeles', 'north', 'men', 'state', 'judge', 'officials', '4', 'house',\n",
    "    'near', 'people', 'sex', 'virginia', 'university', 'court', 'philadelphia', 'fire',\n",
    "    'subway', 'nypd', '1', 'arizona', 'washington', 'women', 'school', 'teen', '1', '2', '3',\n",
    "    'mother', 'woman', 'shows', 'girl', 'driver', 'student', 'child', 'search', 'leaves', 'found',\n",
    "    'man', ':', ',', '(video)', '&', '3', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14',\n",
    "    '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30',\n",
    "    '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46',\n",
    "    '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62',\n",
    "    '-', 'father', 'brother', 'sister', 'son', 'daughter', 'husband', 'wife', 'boyfriend', 'girlfriend',\n",
    "    'boy', '--', '(photo)', '(photos)', 'it\\'s', 'don\\'t', 'can\\'t', 'won\\'t', 'didn\\'t', 'doesn\\'t',\n",
    "    'i\\'m', 'you\\'re', 'he\\'s', 'she\\'s', 'we\\'re', 'they\\'re', 'i\\'ll', 'you\\'ll', 'he\\'ll', 'she\\'ll',\n",
    "    'we\\'ll', 'they\\'ll', 'i\\'ve', 'you\\'ve', 'we\\'ve', 'they\\'ve', 'i\\'d', 'you\\'d', 'he\\'d', 'she\\'d',\n",
    "    'we\\'d', 'they\\'d', 'i\\'ll', 'you\\'ll', 'he\\'ll', 'she\\'ll', 'we\\'ll', 'they\\'ll', 'i\\'ve', 'you\\'ve',\n",
    "    'we\\'ve', 'they\\'ve', 'i\\'d', 'you\\'d', 'he\\'d', 'she\\'d', 'we\\'d', 'they\\'d', 'i\\'ll', 'you\\'ll',\n",
    "    'he\\'ll', 'she\\'ll', 'we\\'ll', 'they\\'ll', 'i\\'ve', 'you\\'ve', 'we\\'ve', 'they\\'ve', 'i\\'d', 'you\\'d',\n",
    "    'he\\'d', 'she\\'d', 'we\\'d', 'they\\'d', 'i\\'ll', 'you\\'ll', 'he\\'ll', 'she\\'ll', 'we\\'ll', 'they\\'ll',\n",
    "    'i\\'ve', 'you\\'ve', 'we\\'ve', 'they\\'ve', 'i\\'d', 'you\\'d', 'he\\'d', 'she\\'d', 'we\\'d', 'they\\'d',\n",
    "    'i\\'ll', 'you\\'ll', 'he\\'ll', 'she\\'ll', 'we\\'ll', 'they\\'ll', 'i\\'ve', 'you\\'ve', 'we\\'ve', 'they\\'ve',\n",
    "    'i\\'d', 'you\\'d', 'he\\'d', 'she\\'d', 'we\\'d', 'they\\'d', 'i\\'ll', 'you\\'ll', 'he\\'ll', 'she\\'ll',\n",
    "    'we\\'ll', 'they\\'ll', 'i\\'ve', 'you\\'ve', 'we\\'ve', 'they\\'ve', 'i\\'d', 'you\\'d', 'he\\'d', 'she\\'d',\n",
    "    'we\\'d', 'they\\'d', 'i\\'ll', 'you\\'ll', 'he\\'ll', 'she\\'ll', 'we\\'ll', 'they\\'ll', 'i\\'ve', 'you\\'ve',\n",
    "    'san', 'high', 'u.s.', 'ohio', 'photo'\n",
    "}\n",
    "\n",
    "# Combine all word counts from titles and descriptions\n",
    "all_word_counts_crime = Counter()\n",
    "for index, row in df_crime.iterrows():\n",
    "    all_word_counts_crime.update(row[\"headline_word_counts\"])\n",
    "    # all_word_counts.update(row[\"description_word_counts\"])\n",
    "\n",
    "# Get the top 50 most common words\n",
    "top_50_crime_words = all_word_counts_crime.most_common(50)\n",
    "top_100_crime_words = all_word_counts_crime.most_common(100)\n",
    "\n",
    "top_crime_words_filtered = [(word, count) for word, count in top_100_crime_words if word not in non_related_words]\n",
    "\n",
    "# Print the filtered list\n",
    "print(\"Top words related to crime:\")\n",
    "for word, count in top_crime_words_filtered:\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "# Combine all word counts from titles and descriptions\n",
    "all_word_counts_science = Counter()\n",
    "for index, row in df_science.iterrows():\n",
    "    all_word_counts_science.update(row[\"headline_word_counts\"])\n",
    "    # all_word_counts.update(row[\"description_word_counts\"])\n",
    "\n",
    "# Get the top 50 most common words\n",
    "top_50_science_words = all_word_counts_science.most_common(50)\n",
    "top_100_science_words = all_word_counts_science.most_common(100)\n",
    "\n",
    "# Filter the top words list to exclude non-crime-related words\n",
    "\n",
    "top_science_words_filtered = [(word, count) for word, count in top_100_science_words if word not in non_related_words]\n",
    "\n",
    "# Print the filtered list\n",
    "print(\"Top words related to science:\")\n",
    "for word, count in top_science_words_filtered:\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "# # Print the top 50 words with their counts\n",
    "# print(\"Top 50 most frequent words:\")\n",
    "# for word, count in top_50_words:\n",
    "#     print(f\"{word}: {count}\")\n",
    "\n",
    "# # Print the top 100 words with their counts\n",
    "# print(\"Top 100 most frequent words:\")\n",
    "# for word, count in top_100_words:\n",
    "#     print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scientist', 'space', 'study', 'nasa', 'science', 'earth', 'mar', 'here', \"'s\", 'suggest', 'like', 'moon', 'ancient', 'brain', 'solar', 'planet', 'research', 'life', 'way', 'help', 'world', 'photo', 'watch', ':', 'time', 'nasa', \"'s\", 'discover', 'rocket', 'climate', 'big', 'mission', 'change', 'star', 'watch', 'alien', 'find', 'sky', 'human', 'neil', 'red', 'rover', 'spacecraft', 'mystery', 'asteroid', 'researcher', 'black', 'astronomer', 'telescope', 'meteor', 'astronaut', 'mysterious', 'universe', 'human', 'planet', 'launch', 'look', 'degrasse', 'station', 'scientific', 'water', 'spacex', 'giant', 'light', 'actually', 'sea', 'world', \"'s\", 'make', 'astronaut', 'well', 'evolution', 'eclipse', 'night', 'amazing', 'reveal', 'tyson', 'reveal', 'face', 'day', 'look', 'huge', 'suggest', 'sun', 'galaxy', 'curiosity', 'future', 'rare'] 88\n",
      "['police', 'shoot', 'cop', 'kill', 'allegedly', 'accuse', 'arrest', 'suspect', 'death', 'shoot', 'dead', 'murder', 'cop', 'charge', 'officer', 'kill', 'prison', 'miss', 'gun', 'allege', 'die', 'guilty', 'shooter', 'case', 'fatally', 'trial', 'attack', 'officer', 'injure', 'charge', 'kill', 'shoot', 'get', 'body', 'arrest', 'fbi', 'black', 'suspect', 'sentence', 'killer', 'life', 'kill', 'dead', ',', 'rape', 'crime', 'fatal', 'catch', 'convict', 'assault', 'gunman', 'deadly', 'face', 'face'] 54\n"
     ]
    }
   ],
   "source": [
    "# Load English tokenizer, tagger, \n",
    "# parser, NER and word vectors \n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "# process top_words_filtered into a string\n",
    "top_crime_words = [word for word, count in top_crime_words_filtered]\n",
    "top_crime_words_str = \" \".join(top_crime_words)\n",
    "\n",
    "top_science_words = [word for word, count in top_science_words_filtered]\n",
    "top_science_words_str = \" \".join(top_science_words)\n",
    "\n",
    "doc_crime = nlp(top_science_words_str)\n",
    "doc_science = nlp(top_crime_words_str)\n",
    "    \n",
    "crime_words = [token.lemma_ for token in doc_crime]\n",
    "print(crime_words, len(crime_words))\n",
    "\n",
    "science_words = [token.lemma_ for token in doc_science]\n",
    "print(science_words, len(science_words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
